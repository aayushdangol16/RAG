{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings,OllamaLLM\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever,create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.retrievers import BM25Retriever,EnsembleRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"RAG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"file.pdf\"\n",
    "loader=PyPDFLoader(file)\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LEAVEPOLICYBAJRATECHNOLOGIESPVT. LTD.\\n1. ThecalendaryearforleavestartsfromthemonthofShrawantotheendofAshadh(normallyJuly16–July15)eachyear.\\n2. EachemployeeisrequiredtoapplyforleavesviatheBizOSsystemandnotviaemail.Leaveapplicationsviaemailwillnotbeentertained.\\n3. Atotalof26workingdays(or208workinghours) inayearisthemaximumleaveanemployeecanearnwhichisequivalentto12daysofsickleaveand14daysofannualleave.\\n4. Annualleave:AnemployeerequestingAnnualleaveforupto3daysneedstoapply5workingdayspriortothedesiredleaveday/s.\\nIfanemployeehastorequestanAnnualleaveoffourormoredaysinarow,s/hemustinformtheirsupervisorandtheHRdepartmentatleastfourweeksor20workingdaysahead.Thisis becauselongleavesdirectlyimpacttheefficiencyoftheprojectthatanemployeeisinvolvedin.\\n5. Sickleave:Anemployeecanapplyforsickleaveatanytimebutwouldrequirepromptcommunicationwiththeirsupervisorand/orcoordinationthroughtheHRdepartmentandtheirrespectiveteam.However, ifthesickleaveexceedsthreedays,theemployeeissupposedtohandovera doctor’s prescriptionordiagnosisreportifrequestedbytheHRdepartment.\\n6. MaternityandPaternityleave:Femaleemployeesareentitledtoamaximumof98dayspaidleavesduringtheirmaternityperiod.Maleemployeesareentitledtoamaximumof15paidpaternityleavesduringthematernityperiodoftheirspouse.However, asperapprovalofthemanagement,leaveconsiderationsaregrantedonacase-by-casebasis.\\n7. Compassionateleave:Anemployeeis entitledtoa maximumof13daysofcompassionateleaveforthelossoftheirimmediatefamilymembers(whichincludesparents,andparents-in-lawformarriedfemaleemployees).\\n8. CompensatoryLeave:CompensatoryLeaveis paidtimeoff foraneligibleemployeehavingworkedadditionalhoursinaworkweek;havingworkedonanofficialofficeclosingday, a holiday, ora scheduledoff day, orwhenaholidayfallsonanemployee'sscheduleddayoff.\\n9. CompensatoryLeavewillbe availedonlywhenthereportingmanagerathis/herdiscretionrequeststheemployeeto workonholiday/weekend.Theemployeecannotdecidetoworkonaholidayandthenseekcompensatoryoff.Fortheallocationofleavein theBizOS,HRmustbeinformedviaticketswithinfiveworkingdaysbythereportingmanager.\\n10.Inthisfiscalyear, therewillbea totalof13paidpublicholidays.Thelist\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'file.pdf', 'page': 0, 'page_label': '1'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200,add_start_index=True)\n",
    "all_splits=text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=OllamaEmbeddings(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorestore=Chroma.from_documents(documents=all_splits,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(all_splits,k=2)\n",
    "retriever=vectorestore.as_retriever(search_type=\"similarity\",k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retriever = EnsembleRetriever(retrievers=[bm25_retriever, retriever],weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \n",
    "which might reference context in the chat history, formulate a standalone question \n",
    "which can be understood without the chat history. Do NOT answer the question, \n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    model, hybrid_retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are provided with context below to help answer the question at the end.\n",
    "If you do not know the answer, simply say \"I don't know.\" Do not attempt to fabricate an answer.\n",
    "Your response should be brief, no more than three sentences.\n",
    "Always conclude with \"Thanks for asking!\" at the end of your answer.\n",
    "\n",
    "{context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(model, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(query):\n",
    "    for chunk in conversational_rag_chain.stream({\"input\": query},config={\"configurable\": {\"session_id\": \"abc123\"}},):\n",
    "        if(list(chunk.keys())[0]==\"answer\"):\n",
    "            print(chunk['answer'],end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company offers the following types of leaves as per their policy:\n",
      "\n",
      "* Annual Leave\n",
      "* Sick Leave\n",
      "* Paid Leaves (including Sundays as a two-day weekend)\n",
      "\n",
      "Thanks for asking!\n",
      "Point 2 from the previous reply states that employees with a negative leave balance during their exit will have that amount deducted from their final compensation. In other words, if an employee has taken more leave than they are entitled to, it will be subtracted from their final pay.\n",
      "\n",
      "Thanks for asking!\n",
      "I don't know. There is no information provided in the context about points 2 and 3 of the previous reply. The conversation only covered leaves such as Annual Leave, Sick Leave, and Paid Leaves. \n",
      "\n",
      "Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    query=input(\"Enter Query\")\n",
    "    if(query==\"bye\"):\n",
    "        break\n",
    "    chat(query)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
