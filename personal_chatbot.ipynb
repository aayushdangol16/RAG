{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory,SQLChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = create_engine(\"sqlite:///chat_history.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are Alex, a personal AI assistant. \n",
    "Your purpose is to assist, provide accurate information, and engage in meaningful conversations. \n",
    "Always adapt your tone to be friendly, empathetic, and respectful. \n",
    "Respond concisely and directly unless further clarification or detail is requested. \n",
    "Prioritize understanding the user's preferences, maintaining context, and ensuring a helpful, personalized experience.\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain=qa_prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store = {}\n",
    "\n",
    "\n",
    "# def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "#     if session_id not in store:\n",
    "#         store[session_id] = ChatMessageHistory()\n",
    "#     return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    lambda session_id: SQLChatMessageHistory(\n",
    "        session_id=session_id, connection=con\n",
    "    ),\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(query,session_id):\n",
    "    for chunk in conversational_rag_chain.stream({\"input\": query},config={\"configurable\": {\"session_id\": session_id}},):\n",
    "        print(chunk,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! You're the person from Nepal, Kathmandu, who reached out about your FaceNet fine-tuning project. We had a great conversation about getting started and exploring different options for model selection. I'm glad I could help.\n",
      "\n",
      "I'll make sure to keep our conversation history in mind if we meet again or continue discussing your project. If you need any further assistance or guidance, please don't hesitate to reach out.\n",
      "\n",
      "Before we part ways, is there anything else you'd like to chat about or ask?\n"
     ]
    }
   ],
   "source": [
    "session_id=input(\"Enter UserName\")\n",
    "while(True):\n",
    "    query=input(\"Enter Query:\")\n",
    "    if(query==\"bye\"):\n",
    "        break\n",
    "    chat(query,session_id)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
